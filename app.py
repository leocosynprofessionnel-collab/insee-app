import streamlit as st
import requests
import pandas as pd
import time
import os
import shutil
import tempfile
import re

# ==============================================================================
# üõ†Ô∏è CONFIGURATION DES DONN√âES
# ==============================================================================

DATASETS_MAP = {
    "Caract√©ristiques de l'Emploi (Princ)": "DS_RP_ACTIVITE_PRINC",
    "Ch√¥mage & Pop. Active (Comp)": "DS_RP_EMPLOI_LR_COMP",
    "Ch√¥mage & Pop. Active (Princ)": "DS_RP_EMPLOI_LR_PRINC",
    "Corps √âlectoral": "DS_ELECTORAL",
    "Cr√©ation d'Entreprises (Secteur)": "DS_SIDE_CREA_ENT_COM",
    "Cr√©ation d'Entreprises √† l'√©chelle supra-communal": "DS_SIDE_CREA_DEP_REG_NAT",
    "Cr√©ation d'√âtablissements": "DS_SIDE_CREA_ETAB_COM",
    "Dipl√¥mes et Formation": "DS_RP_DIPLOMES_PRINC",
    "√âducation et Scolarisation": "DS_RP_EDUCATION",
    "Emploi au Lieu de Travail (Princ)": "DS_RP_EMPLOI_LT_PRINC",
    "√âquipements (Commerce, Services, Sant√©)": "DS_BPE",
    "√âquipements (Enseignement)": "DS_BPE_EDUCATION",
    "√âquipements (Sport, Loisirs, Culture)": "DS_BPE_SPORT_CULTURE",
    "√âquipements - √©volution": "DS_BPE_EVOLUTION",
    "√âtablissements (Sph√®res √âconomie)": "DS_FLORES_ECONOMIC_SPHERE",
    "√âtablissements Salari√©s (17 Secteurs)": "DS_FLORES_A17",
    "√âtablissements Salari√©s (38 Secteurs)": "DS_FLORES_A38",
    "√âtablissements Salari√©s (5 Secteurs)": "DS_FLORES_A5",
    "√âtablissements Salari√©s (88 Secteurs)": "DS_FLORES_A88",
    "√âtat Civil : D√©c√®s": "DS_ETAT_CIVIL_DECES_COMMUNES",
    "√âtat Civil : Naissances": "DS_ETAT_CIVIL_NAIS_COMMUNES",
    "Historique Population (1968-2023)": "DS_POPULATIONS_HISTORIQUES",
    "Logements (Principal)": "DS_RP_LOGEMENT_PRINC",
    "M√©nages & Couples (Principal)": "DS_RP_MENAGES_PRINC",
    "Migrations R√©sidentielles": "DS_RP_MIGRES_PRINC",
    "Navettes Domicile-Travail": "DS_RP_NAVETTES_PRINC",
    "Niveau de vie & Pauvret√© (√Çge)": "DS_FILOSOFI_AGE_TP_NIVVIE",
    "Niveau de vie & Pauvret√© (Logement)": "DS_FILOSOFI_LOG_TP_NIVVIE",
    "Niveau de vie & Pauvret√© (Type M√©nage)": "DS_FILOSOFI_MEN_TP_NIVVIE",
    "Particuliers Employeurs": "DS_FLORES_PE",
    "Pauvret√© : Indicateurs Principaux": "DS_FILOSOFI_CC",
    "Population (Principal)": "DS_RP_POPULATION_PRINC",
    "Populations de r√©f√©rence": "DS_POPULATIONS_REFERENCE",
    "Salaires Priv√© (Sexe & √Çge)": "DS_BTS_SAL_EQTP_SEX_AGE",
    "Salaires Priv√© (Sexe & PCS)": "DS_BTS_SAL_EQTP_SEX_PCS",
    "S√©rie Historique Recensement": "DS_RP_SERIE_HISTORIQUE",
    "Stocks √âtablissements (A10)": "DS_SIDE_STOCKS_ET_COM",
    "Stocks Unit√©s L√©gales (A10)": "DS_SIDE_STOCKS_UL_COM",
    "Tourisme (Capacit√©s H√©bergement)": "DS_TOUR_CAP"
}

# Mapping des Th√©matiques (Regroupement)
THEMES_MAP = {
    "üßë‚Äçü§ù‚Äçüßë Population & dynamiques d√©mographiques": [
        "Population (Principal)", "Populations de r√©f√©rence", "Historique Population (1968-2023)",
        "S√©rie Historique Recensement", "Migrations R√©sidentielles", 
        "√âtat Civil : Naissances", "√âtat Civil : D√©c√®s"
    ],
    "üè† M√©nages, logements & conditions r√©sidentielles": [
        "M√©nages & Couples (Principal)", "Logements (Principal)",
        "Niveau de vie & Pauvret√© (Logement)", "Niveau de vie & Pauvret√© (Type M√©nage)"
    ],
    "üéì √âducation, formation & capital humain": [
        "Dipl√¥mes et Formation", "√âducation et Scolarisation", "√âquipements (Enseignement)"
    ],
    "üíº Emploi, activit√© & march√© du travail": [
        "Caract√©ristiques de l'Emploi (Princ)", "Emploi au Lieu de Travail (Princ)",
        "Ch√¥mage & Pop. Active (Princ)", "Navettes Domicile-Travail"
    ],
    "üè≠ Tissu √©conomique & appareil productif": [
        "√âtablissements Salari√©s (5 Secteurs)", "√âtablissements Salari√©s (17 Secteurs)", 
        "√âtablissements Salari√©s (38 Secteurs)", "√âtablissements Salari√©s (88 Secteurs)",
        "√âtablissements (Sph√®res √âconomie)", "Particuliers Employeurs",
        "Stocks √âtablissements (A10)", "Stocks Unit√©s L√©gales (A10)"
    ],
    "üöÄ Entrepreneuriat & dynamique de cr√©ation": [
        "Cr√©ation d'Entreprises (Secteur)", "Cr√©ation d'√âtablissements", 
        "Cr√©ation d'Entreprises √† l'√©chelle supra-communal"
    ],
    "üí∂ Revenus, salaires & niveaux de vie": [
        "Salaires Priv√© (Sexe & √Çge)", "Salaires Priv√© (Sexe & PCS)",
        "Niveau de vie & Pauvret√© (√Çge)", "Pauvret√© : Indicateurs Principaux"
    ],
    "üó≥Ô∏è Citoyennet√© & vie d√©mocratique": [
        "Corps √âlectoral"
    ],
    "üè•üõçÔ∏è √âquipements, services & qualit√© de vie": [
        "√âquipements (Commerce, Services, Sant√©)", "√âquipements (Sport, Loisirs, Culture)",
        "√âquipements - √©volution"
    ],
    "üß≥ Tourisme & √©conomie pr√©sentielle": [
        "Tourisme (Capacit√©s H√©bergement)"
    ]
}

GEO_API_URL = "https://geo.api.gouv.fr"
INSEE_API_URL = "https://api.insee.fr/melodi/data"
MILLESIME_GEO = "2025"
REFERENCES_DIR = "references"

TIME_BETWEEN_CALLS = 1.5 
PAUSE_ON_ERROR_429 = 60

# ==============================================================================
# üß† MOTEUR TECHNIQUE
# ==============================================================================

def get_safe(url, params=None, headers=None):
    max_retries = 3
    for attempt in range(max_retries):
        try:
            r = requests.get(url, params=params, headers=headers)
            if r.status_code == 200:
                time.sleep(TIME_BETWEEN_CALLS)
                return r
            elif r.status_code == 429:
                time.sleep(PAUSE_ON_ERROR_429)
                continue
            else:
                time.sleep(TIME_BETWEEN_CALLS)
                return r
        except:
            time.sleep(5)
    return None

class LocalReferenceEngine:
    def __init__(self, root_dir, dataset_id):
        self.target_dir = os.path.join(root_dir, dataset_id)
        self.mappings = {}
        self.load_references()

    def load_references(self):
        if not os.path.exists(self.target_dir): return
        files = [f for f in os.listdir(self.target_dir) if f.endswith('.csv')]
        for filename in files:
            key = os.path.splitext(filename)[0]
            try:
                ref_df = pd.read_csv(os.path.join(self.target_dir, filename), sep=';', dtype=str)
                if not ref_df.empty: ref_df.iloc[:, 0] = ref_df.iloc[:, 0].str.strip()
                if ref_df.shape[1] >= 2:
                    self.mappings[key] = pd.Series(ref_df.iloc[:, 1].values, index=ref_df.iloc[:, 0]).to_dict()
            except: pass

    def translate(self, df):
        df_out = df.copy()
        renames = {}
        for col in df_out.columns:
            parts = col.split('.')
            clean_name = parts[-1]
            if clean_name in self.mappings:
                mapping = self.mappings[clean_name]
                df_out[col] = df_out[col].astype(str)
                code_series = df_out[col]
                if clean_name == "GEO":
                    code_series = df_out[col].apply(lambda x: x.split('-', 1)[1] if '-' in x else x).str.strip()
                    df_out[col] = code_series
                
                libelle_col = f"LIBELLE_{clean_name}"
                df_out[libelle_col] = code_series.map(mapping).fillna(code_series)
                renames[col] = f"CODE_{clean_name}"
            elif "OBS_VALUE" in col: renames[col] = "VALEUR"
            elif "OBS_STATUS" in col: renames[col] = "STATUT_DONNEE"
            elif "dim" in parts[0] or "dimensions" in parts[0]: renames[col] = f"CODE_{clean_name}"

        if renames: df_out.rename(columns=renames, inplace=True)
        return df_out

# ==============================================================================
# üåç MOTEUR G√âOGRAPHIQUE AVANC√â
# ==============================================================================

def search_territory(query):
    results = []
    r = get_safe(f"{GEO_API_URL}/communes", params={"nom": query, "fields": "nom,code,codeEpci,codeDepartement,codeRegion", "boost": "population", "limit": 5})
    if r and r.ok:
        for c in r.json():
            results.append({"label": f"üèôÔ∏è Commune : {c['nom']} ({c['code']})", "type": "Commune", "data": c, "id": f"COM-{c['code']}"})
    r = get_safe(f"{GEO_API_URL}/epcis", params={"nom": query, "fields": "nom,code", "limit": 3})
    if r and r.ok:
        for c in r.json():
            results.append({"label": f"‚öôÔ∏è EPCI : {c['nom']}", "type": "EPCI", "data": c, "id": f"EPCI-{c['code']}"})
    r = get_safe(f"{GEO_API_URL}/departements", params={"nom": query, "fields": "nom,code,codeRegion", "limit": 3})
    if r and r.ok:
        for c in r.json():
            results.append({"label": f"üèõÔ∏è D√©partement : {c['nom']} ({c['code']})", "type": "D√©partement", "data": c, "id": f"DEP-{c['code']}"})
    r = get_safe(f"{GEO_API_URL}/regions", params={"nom": query, "fields": "nom,code", "limit": 3})
    if r and r.ok:
        for c in r.json():
            results.append({"label": f"üåç R√©gion : {c['nom']}", "type": "R√©gion", "data": c, "id": f"REG-{c['code']}"})
    return results

def get_comparison_targets_dynamic(selected_item, comparisons):
    targets = []
    main_data = selected_item['data']
    t_type = selected_item['type']
    
    # Cible
    if t_type == "Commune": targets.append({"param": f"{MILLESIME_GEO}-COM-{main_data['code']}", "nom": main_data['nom'], "type": "Cible"})
    elif t_type == "EPCI": targets.append({"param": f"{MILLESIME_GEO}-EPCI-{main_data['code']}", "nom": main_data['nom'], "type": "Cible"})
    elif t_type == "D√©partement": targets.append({"param": f"{MILLESIME_GEO}-DEP-{main_data['code']}", "nom": main_data['nom'], "type": "Cible"})
    elif t_type == "R√©gion": targets.append({"param": f"{MILLESIME_GEO}-REG-{main_data['code']}", "nom": main_data['nom'], "type": "Cible"})

    # Pairs
    if "Communes du m√™me EPCI" in comparisons and t_type == "Commune" and main_data.get('codeEpci'):
        r = get_safe(f"{GEO_API_URL}/epcis/{main_data['codeEpci']}/communes")
        if r and r.ok:
            for c in r.json():
                if c['code'] != main_data['code']: targets.append({"param": f"{MILLESIME_GEO}-COM-{c['code']}", "nom": c['nom'], "type": "Voisin EPCI"})
    if "Communes membres" in comparisons and t_type == "EPCI":
        r = get_safe(f"{GEO_API_URL}/epcis/{main_data['code']}/communes")
        if r and r.ok:
            for c in r.json(): targets.append({"param": f"{MILLESIME_GEO}-COM-{c['code']}", "nom": c['nom'], "type": "Membre EPCI"})
    if "Autres EPCI du D√©partement" in comparisons:
        dept_code = main_data.get('codeDepartement') if t_type == "Commune" else None
        if t_type == "EPCI":
             r_d = get_safe(f"{GEO_API_URL}/epcis/{main_data['code']}", params={"fields": "codeDepartement"})
             if r_d and r_d.ok: dept_code = r_d.json().get('codeDepartement')
        if dept_code:
            r_e = get_safe(f"{GEO_API_URL}/departements/{dept_code}/epcis")
            if r_e and r_e.ok:
                for e in r_e.json():
                    if e['code'] != main_data.get('code') and e['code'] != main_data.get('codeEpci'):
                        targets.append({"param": f"{MILLESIME_GEO}-EPCI-{e['code']}", "nom": e['nom'], "type": "Voisin D√©partement"})
    if "Autres D√©partements de la R√©gion" in comparisons:
        reg_code = main_data.get('codeRegion')
        if reg_code:
            r_d = get_safe(f"{GEO_API_URL}/regions/{reg_code}/departements")
            if r_d and r_d.ok:
                for d in r_d.json():
                    if d['code'] != main_data.get('code') and d['code'] != main_data.get('codeDepartement'):
                        targets.append({"param": f"{MILLESIME_GEO}-DEP-{d['code']}", "nom": d['nom'], "type": "Voisin R√©gion"})
    if "Toutes les R√©gions" in comparisons:
        r_r = get_safe(f"{GEO_API_URL}/regions")
        if r_r and r_r.ok:
            for reg in r_r.json():
                if reg['code'] != main_data.get('code') and reg['code'] != main_data.get('codeRegion'):
                    targets.append({"param": f"{MILLESIME_GEO}-REG-{reg['code']}", "nom": reg['nom'], "type": "Autre R√©gion"})

    # Hi√©rarchie
    if "EPCI" in comparisons and (main_data.get('codeEpci') or t_type == "Commune"):
        c = main_data.get('codeEpci')
        if c: targets.append({"param": f"{MILLESIME_GEO}-EPCI-{c}", "nom": "EPCI", "type": "Parent"})
    if "D√©partement" in comparisons:
        c = main_data.get('codeDepartement')
        if not c and t_type=="EPCI":
             r_d = get_safe(f"{GEO_API_URL}/epcis/{main_data['code']}", params={"fields": "codeDepartement"})
             if r_d and r_d.ok: c = r_d.json().get('codeDepartement')
        if c: targets.append({"param": f"{MILLESIME_GEO}-DEP-{c}", "nom": "D√©partement", "type": "Parent"})
    if "R√©gion" in comparisons and main_data.get('codeRegion'):
        targets.append({"param": f"{MILLESIME_GEO}-REG-{main_data['codeRegion']}", "nom": "R√©gion", "type": "Parent"})
    if "France" in comparisons:
        targets.append({"param": f"{MILLESIME_GEO}-FRANCE-FM", "nom": "France M√©tropolitaine", "type": "National"})

    return targets, f"Export_{main_data['nom'].replace(' ', '_')}"

def process_data_batched(targets, folder_name, selected_datasets_ids):
    with tempfile.TemporaryDirectory() as temp_dir:
        final_dir = os.path.join(temp_dir, folder_name)
        os.makedirs(final_dir)
        status_log = []
        BATCH_SIZE = 5 
        all_geo_params = [t['param'] for t in targets]
        batches = [all_geo_params[i:i + BATCH_SIZE] for i in range(0, len(all_geo_params), BATCH_SIZE)]
        progress_bar = st.progress(0)
        total_steps = len(selected_datasets_ids) * len(batches)
        current_step = 0

        for dataset_name, dataset_id in selected_datasets_ids.items():
            translator = LocalReferenceEngine(REFERENCES_DIR, dataset_id)
            dataset_frames = []
            for batch in batches:
                params_list = [('GEO', code) for code in batch]
                url = f"{INSEE_API_URL}/{dataset_id}"
                r = get_safe(url, params=params_list, headers={'Accept': 'application/json'})
                if r and r.status_code == 200:
                    data = r.json().get("observations", [])
                    if data: dataset_frames.append(pd.json_normalize(data))
                current_step += 1
                progress_bar.progress(min(current_step / total_steps, 1.0))

            if dataset_frames:
                full_df = pd.concat(dataset_frames, ignore_index=True)
                full_df = translator.translate(full_df)
                code_to_name = {t['param'].split('-')[-1]: t['nom'] for t in targets}
                geo_col = next((c for c in full_df.columns if "CODE_GEO" in c), None)
                if geo_col:
                     full_df['LIBELLE_GEOGRAPHIQUE'] = full_df[geo_col].apply(lambda x: code_to_name.get(str(x), x))
                     first_cols = ['LIBELLE_GEOGRAPHIQUE', 'VALEUR']
                     libelle_cols = [c for c in full_df.columns if c.startswith('LIBELLE_') and c != 'LIBELLE_GEOGRAPHIQUE']
                     code_cols = [c for c in full_df.columns if c.startswith('CODE_')]
                     other_cols = [c for c in full_df.columns if c not in first_cols + libelle_cols + code_cols]
                     final_order = [c for c in first_cols if c in full_df.columns] + sorted(libelle_cols) + sorted(code_cols) + sorted(other_cols)
                     full_df = full_df[final_order]
                filename = f"{dataset_name.replace(' ', '_')}.csv"
                full_df.to_csv(os.path.join(final_dir, filename), sep=";", index=False, encoding="utf-8-sig")
                status_log.append(f"‚úÖ {dataset_name} : {len(full_df)} lignes")
            else:
                status_log.append(f"‚ö†Ô∏è {dataset_name} : Aucune donn√©e")

        archive_path = shutil.make_archive(os.path.join(temp_dir, folder_name), 'zip', root_dir=temp_dir, base_dir=folder_name)
        with open(archive_path, "rb") as f: zip_data = f.read()
    return zip_data, status_log

# ==============================================================================
# üé® INTERFACE STREAMLIT
# ==============================================================================

st.set_page_config(page_title="Insee Extraction", page_icon="üåç")
st.markdown("""<style>.stButton>button { width: 100%; background-color: #0068c9; color: white; border-radius: 8px;} div[data-testid="stExpander"] { border: 1px solid #e0e0e0; border-radius: 8px; }</style>""", unsafe_allow_html=True)

st.title("üåç Extracteur Universel des donn√©es de l'INSEE")
st.markdown("Recherchez un territoire, choisissez vos th√©matiques et comparez.")

# 1. RECHERCHE
with st.container():
    search_query = st.text_input("üîç Rechercher un territoire", placeholder="Ex: Dunkerque, Nord, Gironde...")
    if 'search_results' not in st.session_state: st.session_state.search_results = []
    if st.button("Lancer la recherche"):
        with st.spinner("Recherche..."): st.session_state.search_results = search_territory(search_query)

# 2. SELECTION
selected_territory = None
if st.session_state.search_results:
    options = {item['label']: item for item in st.session_state.search_results}
    choice = st.selectbox("üìç R√©sultat exact :", list(options.keys()))
    selected_territory = options[choice]
    st.success(f"Territoire : **{selected_territory['type']} - {selected_territory['data']['nom']}**")

# 3. CONFIGURATION
if selected_territory:
    st.divider()
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("1. Comparaisons")
        t_type = selected_territory['type']
        comparisons = []
        
        st.caption("‚ÜîÔ∏è Pairs (Horizontal)")
        if t_type == "Commune":
            if st.checkbox("Toutes les communes de l'EPCI", value=True): comparisons.append("Communes du m√™me EPCI")
        elif t_type == "EPCI":
            if st.checkbox("Autres EPCI du D√©partement"): comparisons.append("Autres EPCI du D√©partement")
            if st.checkbox("D√©tail de mes Communes membres", value=True): comparisons.append("Communes membres")
        elif t_type == "D√©partement":
            if st.checkbox("Autres D√©partements de la R√©gion"): comparisons.append("Autres D√©partements de la R√©gion")
        elif t_type == "R√©gion":
            if st.checkbox("Toutes les R√©gions de France"): comparisons.append("Toutes les R√©gions")
        
        st.caption("‚ÜïÔ∏è Hi√©rarchie (Vertical)")
        if t_type == "Commune":
            if st.checkbox("EPCI", value=True): comparisons.append("EPCI")
            if st.checkbox("D√©partement"): comparisons.append("D√©partement")
            if st.checkbox("R√©gion"): comparisons.append("R√©gion")
        elif t_type == "EPCI":
            if st.checkbox("D√©partement"): comparisons.append("D√©partement")
            if st.checkbox("R√©gion"): comparisons.append("R√©gion")
        elif t_type == "D√©partement":
            if st.checkbox("R√©gion"): comparisons.append("R√©gion")
        if st.checkbox("France M√©tropolitaine", value=True): comparisons.append("France")

    with col2:
        st.subheader("2. Donn√©es")
        
        # --- NOUVEAU SELECTEUR DE TH√àMES ---
        st.write("üìÇ **S√©lection Rapide par Th√©matique**")
        selected_themes = st.multiselect("Ajouter des th√©matiques enti√®res :", list(THEMES_MAP.keys()))
        
        # Case Tout S√©lectionner
        select_all = st.checkbox("‚úÖ Tout s√©lectionner (toutes les bases)")
        
        # Calcul de la s√©lection par d√©faut
        default_datasets = []
        if select_all:
            default_datasets = list(DATASETS_MAP.keys())
        elif selected_themes:
            # On ajoute les datasets des th√®mes choisis
            for theme in selected_themes:
                default_datasets.extend(THEMES_MAP[theme])
            # On d√©doublonne
            default_datasets = list(set(default_datasets))
        else:
            # D√©faut minimal si rien n'est coch√©
            default_datasets = ["Dipl√¥mes et Formation", "Caract√©ristiques de l'Emploi (Princ)"]

        # Le Multiselect Final (modifiable par l'utilisateur)
        st.write("üìù **Ajuster la s√©lection pr√©cise :**")
        datasets = st.multiselect("Bases de donn√©es", list(DATASETS_MAP.keys()), default=default_datasets)

    st.divider()
    if st.button("üöÄ Extraire les donn√©es"):
        if not datasets:
            st.error("Aucune donn√©e s√©lectionn√©e.")
        else:
            target_ids = {k: DATASETS_MAP[k] for k in datasets}
            with st.spinner("Traitement en cours..."):
                targets, folder_name = get_comparison_targets_dynamic(selected_territory, comparisons)
                st.info(f"üì¶ {len(targets)} zones g√©ographiques.")
                zip_file, logs = process_data_batched(targets, folder_name, target_ids)
                st.success("Termin√© !")
                st.download_button(f"üì• T√©l√©charger {folder_name}.zip", zip_file, f"{folder_name}.zip", "application/zip")
                with st.expander("D√©tails"):
                     for l in logs: st.write(l)